{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0IAEoV3oGlw3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HDiQckfnvdPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6c7f74-6fad-4693-8cb3-6a33aafa7524"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/IMDB Dataset.csv\")\n"
      ],
      "metadata": {
        "id": "ZuLflsQ4HItJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
      ],
      "metadata": {
        "id": "oa-fY6KzHJWu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(n=5000, random_state=42)\n"
      ],
      "metadata": {
        "id": "f59EtW5YHRlZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def tokenize_review(review):\n",
        "    tokens = [token.text for token in nlp(review.lower()) if not token.is_stop and not token.is_punct]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "l8CABYerHVPl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"tokenize_review\"] = df[\"review\"].apply(tokenize_review)"
      ],
      "metadata": {
        "id": "uXUJQ9D9HYV6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oz1NtbEoz6cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = Counter([token for review in df['tokenize_review'] for token in review])\n",
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "word_to_index = {word: idx+1 for idx, word in enumerate(vocab)}  # Add 1 to reserve index 0 for padding\n",
        "\n"
      ],
      "metadata": {
        "id": "USoI8G87HucA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file_path='vocab_data'\n",
        "# Open the file in write mode\n",
        "with open(vocab_file_path, \"w\") as file:\n",
        "    # Write each word in the vocab list to the file\n",
        "    for word in vocab:\n",
        "        file.write(word + \"\\n\")\n",
        "\n",
        "print(\"Vocabulary saved to:\", vocab_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMpff2_Nwne-",
        "outputId": "49491ca5-e039-4b64-ea01-e0404d97ebf7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary saved to: vocab_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index_file_path = \"word_to_index.txt\"\n",
        "\n",
        "# Open the file in write mode\n",
        "with open(word_to_index_file_path, \"w\") as file:\n",
        "    # Write each key-value pair in the word_to_index dictionary to the file\n",
        "    for word, index in word_to_index.items():\n",
        "        file.write(f\"{word}: {index}\\n\")\n",
        "\n",
        "print(\"Word to Index mapping saved to:\", word_to_index_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwD7nkr7wtHi",
        "outputId": "a6e54560-dcc5-4fe3-8e26-b4c6ceec3ca0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word to Index mapping saved to: word_to_index.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numericalize_review(review_tokens):\n",
        "    return [word_to_index[token] for token in review_tokens]\n",
        "\n",
        "df[\"numericalized_review\"] = df[\"tokenize_review\"].apply(numericalize_review)\n"
      ],
      "metadata": {
        "id": "kfurHoOxJE_y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"review.csv\", index=False)"
      ],
      "metadata": {
        "id": "OYHI_ziF0Rtp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(df[\"numericalized_review\"].apply(len))\n",
        "def pad_sequence(sequence, max_len):\n",
        "    return sequence + [0]*(max_len - len(sequence))\n",
        "\n",
        "df[\"padded_review\"] = df[\"numericalized_review\"].apply(lambda x: pad_sequence(x, max_len))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2_8JM3UnJ8b7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[\"padded_review\"].values, df[\"sentiment\"].values, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "_ab03JE-L3DM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n"
      ],
      "metadata": {
        "id": "b3Y0V2d7L60O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "i7IILenJL-Bi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "e8gdIsNSMJFG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_workers = 2"
      ],
      "metadata": {
        "id": "tJSwJnnKMRq_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n"
      ],
      "metadata": {
        "id": "Pz5o7fF-MSYQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n"
      ],
      "metadata": {
        "id": "TYVTfsfCM8c4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab) + 1  # Add 1 for padding token\n",
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "output_dim = 1\n",
        "n_layers = 2\n",
        "dropout = 0.5\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n"
      ],
      "metadata": {
        "id": "bmEu87bhMZJp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout).to(device)\n"
      ],
      "metadata": {
        "id": "Kd97L8gGNSNJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n"
      ],
      "metadata": {
        "id": "8OQwsumxy0-M"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for X_batch, y_batch in tqdm(iterator, desc='Training'):\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(X_batch).squeeze(1)\n",
        "        loss = criterion(predictions, y_batch.float())\n",
        "        acc = accuracy_score(torch.round(torch.sigmoid(predictions)).cpu().detach().numpy(), y_batch.cpu().detach().numpy())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "H8ke9UNay4qh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in tqdm(iterator, desc='Evaluating'):\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            predictions = model(X_batch).squeeze(1)\n",
        "            loss = criterion(predictions, y_batch.float())\n",
        "            acc = accuracy_score(torch.round(torch.sigmoid(predictions)).cpu().detach().numpy(), y_batch.cpu().detach().numpy())\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "VbSqqAWry_QU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 3\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, test_loader, criterion)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "FAjzRs9mwSwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f577e6a-5fa1-43fe-fa88-5d236829caed"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/63 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Training: 100%|██████████| 63/63 [46:33<00:00, 44.34s/it]\n",
            "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Evaluating: 100%|██████████| 16/16 [00:26<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.695 | Train Acc: 50.25%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 50.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/63 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Training: 100%|██████████| 63/63 [41:56<00:00, 39.95s/it]\n",
            "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Evaluating: 100%|██████████| 16/16 [00:26<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02\n",
            "\tTrain Loss: 0.694 | Train Acc: 49.21%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/63 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Training: 100%|██████████| 63/63 [40:02<00:00, 38.13s/it]\n",
            "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Evaluating: 100%|██████████| 16/16 [00:26<00:00,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03\n",
            "\tTrain Loss: 0.694 | Train Acc: 48.56%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 49.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best-model.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "tYD0g2Nw9EhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d277da72-ee59-45c0-832b-6089c05e40bd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(47041, 128)\n",
              "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the new dataset\n",
        "new_df = pd.read_csv(\"/content/drive/MyDrive/new file\")"
      ],
      "metadata": {
        "id": "uRrX0mvheS5V"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define a function for making predictions\n",
        "def predict(model, data_loader):\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in tqdm(data_loader, desc='Predicting'):\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            outputs = model(X_batch).squeeze(1)\n",
        "            preds = torch.round(torch.sigmoid(outputs))\n",
        "\n",
        "            predictions.extend(preds.cpu().detach().numpy())\n",
        "            targets.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    return predictions, targets\n",
        "\n",
        "# Make predictions on the test dataset\n",
        "test_predictions, test_targets = predict(model, test_loader)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "test_accuracy = accuracy_score(test_targets, test_predictions)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_targets, test_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_targets, test_predictions))\n"
      ],
      "metadata": {
        "id": "hyOhhmvskoJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da995c1f-6237-4894-b9ff-406965de3f42"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting:   0%|          | 0/16 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Predicting: 100%|██████████| 16/16 [00:27<00:00,  1.53s/it]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Predicting: 100%|██████████| 16/16 [00:27<00:00,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.506\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.67       506\n",
            "           1       0.00      0.00      0.00       494\n",
            "\n",
            "    accuracy                           0.51      1000\n",
            "   macro avg       0.25      0.50      0.34      1000\n",
            "weighted avg       0.26      0.51      0.34      1000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[506   0]\n",
            " [494   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}